{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df22e71-de37-4133-a9ef-0841a941bb12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!apt-get update && apt install -y aria2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45a475-0fd4-4e83-8cbb-878a77fde75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \"/workspace/runpod-slim/ComfyUI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac20d7-4593-4e4f-824e-6febbc7221ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install uv\n",
    "!/workspace/runpod-slim/ComfyUI/.venv/bin/python3 -m 'pip install uv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b58b6f0-96c8-4697-9e64-8a5bac221180",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# @title Def Url Type Latest\n",
    "def get_url_type(url):\n",
    "    \"\"\"\n",
    "    Checks if a URL is from Hugging Face or Civitai.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL string to check.\n",
    "\n",
    "    Returns:\n",
    "        str: 'huggingface' if from Hugging Face, 'civitai' if from Civitai,\n",
    "             'unknown' otherwise.\n",
    "    \"\"\"\n",
    "    if not isinstance(url, str) or not url.strip():\n",
    "        return 'unknown'\n",
    "\n",
    "    lower_url = url.lower()\n",
    "\n",
    "    if 'huggingface.co' in lower_url:\n",
    "        return 'huggingface'\n",
    "    elif 'civitai.com' in lower_url:\n",
    "        return 'civitai'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "print(\"Function 'get_url_type' created.\")\n",
    "\n",
    "# @title Hugging Face Downloader Latest\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "from huggingface_hub import hf_hub_download, login # Import login here too\n",
    "import zipfile # Import zipfile\n",
    "\n",
    "def download_huggingface_model(url, hf_token, save_directory, alias=None):\n",
    "    \"\"\"\n",
    "    Downloads a model or file from Hugging Face using a direct URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): The Hugging Face 'resolve' or 'blob' URL.\n",
    "        hf_token (str): The Hugging Face Personal Access Token (can be empty).\n",
    "        save_directory (str): The local directory to save the file.\n",
    "        alias (str, optional): An optional alias for the saved filename.\n",
    "                               Defaults to None.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Processing Hugging Face URL: {url} ---\")\n",
    "\n",
    "    if not url or not save_directory:\n",
    "        print(\"‚ùå Error: Hugging Face URL or save directory is empty.\")\n",
    "        return\n",
    "\n",
    "    # Ensure save directory exists\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    repo_id = None\n",
    "    filename_from_url = None\n",
    "    repo_type = None\n",
    "\n",
    "    # Regex patterns to handle different URL structures (models and datasets)\n",
    "    # Pattern for models: huggingface.co/namespace/repo/resolve/branch/filename\n",
    "    match_model = re.search(r\"huggingface\\.co/([^/]+/[^/]+)/(?:resolve|blob)/[^/]+/(.+)$\", url)\n",
    "\n",
    "    # Pattern for datasets: huggingface.co/datasets/namespace/repo/resolve/branch/filename\n",
    "    match_dataset = re.search(r\"huggingface\\.co/datasets/([^/]+/[^/]+)/(?:resolve|blob)/[^/]+/(.+)$\", url)\n",
    "\n",
    "\n",
    "    if match_model:\n",
    "        repo_id, filename_from_url = match_model.groups()\n",
    "        repo_type = \"model\"\n",
    "    elif match_dataset:\n",
    "        repo_id, filename_from_url = match_dataset.groups()\n",
    "        repo_type = \"dataset\"\n",
    "    else:\n",
    "        print(\"‚ùå Error: Hugging Face URL does not match the expected 'resolve/' or 'blob/' format for models or datasets.\")\n",
    "        return\n",
    "\n",
    "\n",
    "    print(f\"üì¶ Attempting to download '{filename_from_url}' from repo '{repo_id}' (Type: {repo_type})...\")\n",
    "\n",
    "    try:\n",
    "        # Use hf_hub_download to handle the download\n",
    "        downloaded_path = hf_hub_download(\n",
    "            repo_id=repo_id,\n",
    "            filename=filename_from_url,\n",
    "            token=hf_token if hf_token else None, # Pass token if provided\n",
    "            cache_dir=save_directory,  # cache directly into target (optional, but can speed up)\n",
    "            local_dir=save_directory,  # save directly into target\n",
    "            local_dir_use_symlinks=False, # Avoid symlinks\n",
    "            resume_download=True, # Enable resume\n",
    "            repo_type=repo_type # Specify repo type\n",
    "        )\n",
    "\n",
    "        # Determine the final save path\n",
    "        final_save_path = downloaded_path # Start with the path from hf_hub_download\n",
    "\n",
    "        # Handle alias if provided and not empty\n",
    "        if alias and alias.strip():\n",
    "            # Preserve original extension if alias doesn't have one\n",
    "            original_extension = os.path.splitext(filename_from_url)[1]\n",
    "            alias_with_extension = alias.strip()\n",
    "            if not os.path.splitext(alias_with_extension)[1]:\n",
    "                 alias_with_extension += original_extension\n",
    "\n",
    "            new_path = os.path.join(save_directory, alias_with_extension)\n",
    "\n",
    "            # Rename the file if it was downloaded and needs renaming\n",
    "            if os.path.exists(final_save_path) and final_save_path != new_path:\n",
    "                 try:\n",
    "                    os.rename(final_save_path, new_path)\n",
    "                    print(f\"‚úÖ Renamed to alias: {os.path.basename(new_path)}\")\n",
    "                    final_save_path = new_path # Update the final path\n",
    "                 except OSError as e:\n",
    "                    print(f\"‚ùå Error renaming file to alias '{alias_with_extension}': {e}\")\n",
    "            elif not os.path.exists(final_save_path):\n",
    "                 print(f\"‚ö†Ô∏è Could not rename file, downloaded path not found: {final_save_path}\")\n",
    "            # If final_save_path == new_path, it was already downloaded with the correct name\n",
    "\n",
    "\n",
    "        if os.path.exists(final_save_path):\n",
    "             size_mb = round(os.path.getsize(final_save_path) / (1024*1024), 2)\n",
    "             print(f\"‚úÖ Download complete! File saved to: {final_save_path} ({size_mb} MB)\")\n",
    "\n",
    "             # --- Added Zip Extraction Logic ---\n",
    "             if final_save_path.lower().endswith('.zip'):\n",
    "                 print(f\"Attempting to extract zip file: {os.path.basename(final_save_path)}\")\n",
    "                 try:\n",
    "                     with zipfile.ZipFile(final_save_path, 'r') as zip_ref:\n",
    "                         zip_ref.extractall(save_directory)\n",
    "                     print(f\"‚úÖ Successfully extracted zip file to: {save_directory}\")\n",
    "                     # Optional: Remove the zip file after extraction\n",
    "                     # os.remove(final_save_path)\n",
    "                     # print(f\"Removed zip file: {os.path.basename(final_save_path)}\")\n",
    "                 except zipfile.BadZipFile:\n",
    "                     print(f\"‚ùå Error: Downloaded file is not a valid zip file: {os.path.basename(final_save_path)}\")\n",
    "                 except Exception as e:\n",
    "                     print(f\"‚ùå Error extracting zip file {os.path.basename(final_save_path)}: {e}\")\n",
    "             # --- End of Zip Extraction Logic ---\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(f\"‚ùå Download completed by hf_hub_download, but file not found at expected path: {final_save_path}\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during Hugging Face download: {e}\")\n",
    "        print(\"Please check the URL, repo ID, filename, and token (if required).\")\n",
    "        # Optional: print full traceback for debugging\n",
    "        # import traceback\n",
    "        # traceback.print_exc()\n",
    "\n",
    "\n",
    "print(\"Function 'download_huggingface_model' modified for zip extraction.\")\n",
    "\n",
    "# @title üöÄ Civitai Downloader (Auto Redirect Fix)\n",
    "import os, re, subprocess, requests\n",
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "def download_civitai_model(url, civitai_token, save_directory, alias=None):\n",
    "    \"\"\"\n",
    "    Auto-follows Civitai redirect to Cloudflare (no header needed after step 1)\n",
    "    and downloads with aria2c.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Processing Civitai URL: {url} ---\")\n",
    "\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "    headers = {\"User-Agent\": \"ColabUniversalDownloader/1.0\"}\n",
    "    if civitai_token:\n",
    "        headers[\"Authorization\"] = f\"Bearer {civitai_token}\"\n",
    "\n",
    "    # Step 1Ô∏è‚É£: Get real redirect link (Cloudflare URL)\n",
    "    print(\"üîó Getting redirect URL from Civitai...\")\n",
    "    try:\n",
    "        head = requests.head(url, headers=headers, allow_redirects=False, timeout=10)\n",
    "        redirect_url = head.headers.get(\"Location\")\n",
    "        if not redirect_url:\n",
    "            print(f\"‚ùå Failed to get redirect (status={head.status_code}).\")\n",
    "            return\n",
    "        print(f\"‚úÖ Got redirect URL:\\n{redirect_url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error getting redirect: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 2Ô∏è‚É£: Get filename\n",
    "    filename = alias or os.path.basename(urlparse(redirect_url).path) or \"model.safetensors\"\n",
    "    save_path = os.path.join(save_directory, filename)\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"‚è© File already exists: {filename}\")\n",
    "        return\n",
    "\n",
    "    # Step 3Ô∏è‚É£: Run aria2c without token header\n",
    "    cmd = [\n",
    "        \"aria2c\",\n",
    "        redirect_url,\n",
    "        \"--console-log-level=notice\",\n",
    "        \"-c\", \"-s\", \"16\", \"-x\", \"16\", \"-k\", \"10M\",\n",
    "        \"-d\", save_directory,\n",
    "        \"-o\", filename\n",
    "    ]\n",
    "    print(\"\\nüöÄ Running aria2c command:\")\n",
    "    print(\" \".join(cmd))\n",
    "    print(\"=====================================\")\n",
    "\n",
    "    result = subprocess.run(cmd, text=True, capture_output=True)\n",
    "    print(result.stdout)\n",
    "    print(result.stderr)\n",
    "\n",
    "    if result.returncode == 0 and os.path.exists(save_path):\n",
    "        size_mb = round(os.path.getsize(save_path)/(1024*1024), 2)\n",
    "        print(f\"‚úÖ Download complete: {save_path} ({size_mb} MB)\")\n",
    "    else:\n",
    "        print(f\"‚ùå aria2c failed (exit {result.returncode}).\")\n",
    "\n",
    "print(\"Function 'download_civitai_model' now follows redirects properly.\")\n",
    "\n",
    "# @title MODEL CHOOSE\n",
    "INFERENCE_TYPE = \"QWEN\" # @param [\"QWEN\",\"SDXL\",\"UPSCALE\"]\n",
    "if(INFERENCE_TYPE == \"QWEN\"):\n",
    "  MODEL= f\"\"\"\n",
    "https://huggingface.co/Phr00t/Qwen-Image-Edit-Rapid-AIO/resolve/main/v19/Qwen-Rapid-AIO-NSFW-v19.safetensors|/workspace/runpod-slim/ComfyUI/models/checkpoints|Qwen-Rapid-AIO-NSFW-v19.safetensors,\n",
    "\"\"\"\n",
    "elif(INFERENCE_TYPE == \"SDXL\"):\n",
    "   MODEL= \"\"\"\n",
    "https://civitai.com/api/download/models/2285644?type=Model&format=SafeTensor&size=pruned&fp=fp16|/workspace/runpod-slim/ComfyUI/models/checkpoints|ultra-RealisticV2.0.safetensors,\n",
    "https://huggingface.co/alexgenovese/controlnet/resolve/dde0b026ee9fbcb7cb8c262bfffa94dc00c87c69/exp-schp-201908270938-pascal-person-part.pth|/workspace/runpod-slim/ComfyUI/models/schp|exp-schp-201908270938-pascal-person-part.pth\n",
    "\"\"\"\n",
    "elif(INFERENCE_TYPE == \"UPSCALE\"):\n",
    "#    !git clone https://github.com/viperyl/ComfyUI-RGT /content/ComfyUI/custom_nodes/comfyui-rgt\n",
    "   MODEL= \"\"\"\n",
    "  https://civitai.com/api/download/models/2285644?type=Model&format=SafeTensor&size=pruned&fp=fp16|/content/ComfyUI/models/checkpoints|ultra-RealisticV2.0.safetensors\n",
    "  https://huggingface.co/gemasai/4x_NMKD-Siax_200k/resolve/main/4x_NMKD-Siax_200k.pth|/content/ComfyUI/models/upscale|4x_NMKD-Siax_200k.pth\n",
    "  \"\"\"\n",
    "elif(INFERENCE_TYPE == \"GGUF\"):\n",
    "#    !git clone https://github.com/viperyl/ComfyUI-RGT /content/ComfyUI/custom_nodes/comfyui-rgt\n",
    "   MODEL= \"\"\"\n",
    "   https://huggingface.co/Arunk25/Qwen-Image-Edit-Rapid-AIO-GGUF/resolve/main/v18/Qwen-Rapid-NSFW-v18_Q6_K.gguf|/workspace/runpod-slim/ComfyUI/models/unet|Qwen-Rapid-NSFW-v18_Q6_K.gguf,\n",
    "   https://huggingface.co/chatpig/qwen2.5-vl-7b-it-gguf/resolve/main/qwen2.5-vl-7b-it-q4_0.gguf|/workspace/runpod-slim/ComfyUI/models/text_encoders|qwen2.5-vl-7b-it-q4_0.gguf,\n",
    "   https://huggingface.co/chatpig/qwen2.5-vl-7b-it-gguf/resolve/main/mmproj-qwen2.5-vl-7b-it-q4_0.gguf|/workspace/runpod-slim/ComfyUI/models/text_encoders|mmproj-qwen2.5-vl-7b-it-q4_0.gguf\n",
    "  \"\"\"\n",
    "print(f\"üìå MODEL: {MODEL}\")\n",
    "\n",
    "\n",
    "#@title Download multiline\n",
    "import re\n",
    "\n",
    "def parse_model_list(MODEL: str):\n",
    "    \"\"\"\n",
    "    Parse string MODEL berformat:\n",
    "    url|directory|alias, url2|directory2|alias2,\n",
    "    (boleh multiline)\n",
    "    Return: list of (url, directory, alias_or_None)\n",
    "    \"\"\"\n",
    "    if not MODEL or not MODEL.strip():\n",
    "        return []\n",
    "\n",
    "    # Gabung semua whitespace, lalu split by comma\n",
    "    raw_items = [x.strip() for x in MODEL.strip().split(\",\")]\n",
    "\n",
    "    items = []\n",
    "    for raw in raw_items:\n",
    "        if not raw:\n",
    "            continue\n",
    "\n",
    "        parts = [p.strip() for p in raw.split(\"|\")]\n",
    "        # minimal: url|dir\n",
    "        if len(parts) < 2:\n",
    "            print(f\"‚ö†Ô∏è Skip (format salah, butuh url|dir[|alias]): {raw}\")\n",
    "            continue\n",
    "\n",
    "        url = parts[0]\n",
    "        directory = parts[1]\n",
    "        alias = parts[2] if len(parts) >= 3 and parts[2].strip() else None\n",
    "\n",
    "        if not url or not directory:\n",
    "            print(f\"‚ö†Ô∏è Skip (url/dir kosong): {raw}\")\n",
    "            continue\n",
    "\n",
    "        items.append((url, directory, alias))\n",
    "\n",
    "    return items\n",
    "\n",
    "\n",
    "def detect_source(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Return: 'civitai' | 'huggingface' | 'unknown'\n",
    "    \"\"\"\n",
    "    u = (url or \"\").lower()\n",
    "\n",
    "    # Civitai: domain atau endpoint download API\n",
    "    if \"civitai.com\" in u:\n",
    "        return \"civitai\"\n",
    "\n",
    "    # Hugging Face: domain huggingface.co\n",
    "    if \"huggingface.co\" in u:\n",
    "        return \"huggingface\"\n",
    "\n",
    "    return \"unknown\"\n",
    "\n",
    "\n",
    "def download_models_from_var(\n",
    "    MODEL: str,\n",
    "    civitai_token: str = \"\",\n",
    "    hf_token: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Parse MODEL (url|dir|alias) dipisah koma\n",
    "    2) Detect sumber (civitai/huggingface)\n",
    "    3) Panggil downloader yang sesuai\n",
    "    \"\"\"\n",
    "    entries = parse_model_list(MODEL)\n",
    "    if not entries:\n",
    "        print(\"‚ùå MODEL kosong / tidak ada entry valid.\")\n",
    "        return\n",
    "\n",
    "    print(f\"üìå Total entry: {len(entries)}\")\n",
    "\n",
    "    for i, (url, directory, alias) in enumerate(entries, start=1):\n",
    "        src = detect_source(url)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"#{i} | Source: {src}\")\n",
    "        print(f\"URL : {url}\")\n",
    "        print(f\"DIR : {directory}\")\n",
    "        print(f\"ALIAS: {alias or '(auto)'}\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        try:\n",
    "            if src == \"civitai\":\n",
    "                download_civitai_model(\n",
    "                    url=url,\n",
    "                    civitai_token=civitai_token,\n",
    "                    save_directory=directory,\n",
    "                    alias=alias\n",
    "                )\n",
    "            elif src == \"huggingface\":\n",
    "                download_huggingface_model(\n",
    "                    url=url,\n",
    "                    hf_token=hf_token,\n",
    "                    save_directory=directory,\n",
    "                    alias=alias\n",
    "                )\n",
    "            else:\n",
    "                print(f\"‚ùå Unknown source (skip): {url}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saat download entry #{i}: {e}\")\n",
    "\n",
    "civitai_token = \"d5fc0862e84c34478cc5903f75816c20\"\n",
    "hf_token = \"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\"\n",
    "\n",
    "download_models_from_var(MODEL, civitai_token=civitai_token, hf_token=hf_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f478ed68-97c0-4c5f-ac67-c7f086fe2a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `hf`CLI if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "The token `jpesddintk` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `jpesddintk`\n"
     ]
    }
   ],
   "source": [
    "# !hf auth login  --token \"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\"\n",
    "!hf auth login  --token \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c55288a-2282-4ea0-af88-35c11806b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env REPO_ID = {\"jpesddin/raw-ig\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45033ee-a5ed-4497-92a5-46af75720dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from huggingface_hub import HfApi, hf_hub_download\n",
    "from huggingface_hub.hf_api import RepoFile\n",
    "\n",
    "# ================= CONFIG =================\n",
    "LOCAL_DIR = \"/workspace/runpod-slim/ComfyUI/input/\"\n",
    "REPO_ID   = os.getenv(\"REPO_ID\")            # wajib ada\n",
    "PREFIX    = \"raw/krystalwang99\"\n",
    "\n",
    "# ekstensi yang MAU didownload\n",
    "ALLOW_EXT = {\".mp4\"}   # edit bebas\n",
    "# ALLOW_EXT = {\".png\", \".jpg\", \".jpeg\", \".webp\"}   # edit bebas\n",
    "MAX_WORKERS = 8\n",
    "# =========================================\n",
    "\n",
    "os.makedirs(LOCAL_DIR, exist_ok=True)\n",
    "api = HfApi()\n",
    "\n",
    "items = list(api.list_repo_tree(\n",
    "    repo_id=REPO_ID,\n",
    "    repo_type=\"dataset\",\n",
    "    revision=\"main\",\n",
    "    path_in_repo=PREFIX,\n",
    "    recursive=True,\n",
    "))\n",
    "\n",
    "# ambil file + filter ekstensi\n",
    "files = []\n",
    "for it in items:\n",
    "    if isinstance(it, RepoFile):\n",
    "        ext = os.path.splitext(it.path)[1].lower()\n",
    "        if ext in ALLOW_EXT:\n",
    "            files.append(it.path)\n",
    "\n",
    "print(\"Total files after filter:\", len(files))\n",
    "\n",
    "def dl(path_in_repo: str):\n",
    "    return hf_hub_download(\n",
    "        repo_id=REPO_ID,\n",
    "        repo_type=\"dataset\",\n",
    "        filename=path_in_repo,\n",
    "        local_dir=LOCAL_DIR,\n",
    "        local_dir_use_symlinks=False,\n",
    "        resume_download=True,\n",
    "    )\n",
    "\n",
    "ok = 0\n",
    "fail = 0\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    futs = {ex.submit(dl, f): f for f in files}\n",
    "    for i, fut in enumerate(as_completed(futs), 1):\n",
    "        f = futs[fut]\n",
    "        try:\n",
    "            fut.result()\n",
    "            ok += 1\n",
    "        except Exception as e:\n",
    "            fail += 1\n",
    "            print(\"FAIL:\", f, \"->\", repr(e))\n",
    "        if i % 50 == 0 or i == len(files):\n",
    "            print(f\"Progress: {i}/{len(files)} (ok={ok}, fail={fail}, workers={MAX_WORKERS})\")\n",
    "\n",
    "print(\"DONE:\", {\"ok\": ok, \"fail\": fail})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdd54ed-59b4-4ea6-a0d8-1c1de1132c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title DOWNLOAD DATASET FOROM HF\n",
    "LOCAL_DIR = \"/workspace/runpod-slim/ComfyUI/input/\" # @param {\"type\":\"string\"}\n",
    "# REPO_URL = \"Esddin/raw-img\" # @param {\"type\":\"string\"}\n",
    "REPO_URL = \"gmesddin/raw-asia\" # @param {\"type\":\"string\"}\n",
    "PATTERN = \"raw/moguu__mogu/*\" # @param {\"type\":\"string\"}\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=REPO_URL,\n",
    "    repo_type=\"dataset\",\n",
    "    revision=\"main\",\n",
    "    local_dir=LOCAL_DIR,\n",
    "    allow_patterns=[PATTERN]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fd08cc-678a-4b6d-95fe-8ed78f503d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# ================= CONFIG =================\n",
    "SUBJECT = \"cxxsomi\"\n",
    "\n",
    "SRC = Path(\"/workspace/runpod-slim/ComfyUI/output\")\n",
    "DST_ROOT = Path(f\"/workspace/runpod-slim/{SUBJECT}\")\n",
    "INBOX = DST_ROOT / \"inbox\"   # tempat file yang siap diupload\n",
    "\n",
    "REPO_ID = \"gmesddin/raw-asia\"\n",
    "PATH_IN_REPO = f\"qwen/{SUBJECT}_qwen\"\n",
    "\n",
    "INTERVAL = 60  # detik\n",
    "# =========================================\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\") or \"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\"\n",
    "if not HF_TOKEN:\n",
    "    raise RuntimeError(\"HF_TOKEN kosong (set env HF_TOKEN dulu, jangan hardcode)\")\n",
    "\n",
    "api = HfApi(token=HF_TOKEN)\n",
    "\n",
    "INBOX.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def unique_dest_path(dst_dir: Path, filename: str) -> Path:\n",
    "    \"\"\"\n",
    "    Kalau filename sudah ada di dst_dir, bikin nama baru:\n",
    "    name.ext -> name__dup2.ext -> name__dup3.ext -> ...\n",
    "    \"\"\"\n",
    "    base = Path(filename).stem\n",
    "    ext  = Path(filename).suffix\n",
    "    candidate = dst_dir / f\"{base}{ext}\"\n",
    "    if not candidate.exists():\n",
    "        return candidate\n",
    "\n",
    "    i = 2\n",
    "    while True:\n",
    "        candidate = dst_dir / f\"{base}__dup{i}{ext}\"\n",
    "        if not candidate.exists():\n",
    "            return candidate\n",
    "        i += 1\n",
    "\n",
    "def move_with_rename(src_path: Path, dst_dir: Path) -> Path:\n",
    "    dst_path = unique_dest_path(dst_dir, src_path.name)\n",
    "    shutil.move(str(src_path), str(dst_path))\n",
    "    return dst_path\n",
    "\n",
    "print(\"üöÄ Auto-upload started\")\n",
    "print(f\"SUBJECT  : {SUBJECT}\")\n",
    "print(f\"INTERVAL : {INTERVAL} detik\")\n",
    "print(f\"HF PATH  : {PATH_IN_REPO}\")\n",
    "print(\"=================================\\n\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # 1) MOVE file dari SRC yang prefix-nya SUBJECT -> INBOX\n",
    "        moved = []\n",
    "        for p in SRC.glob(f\"{SUBJECT}*\"):\n",
    "            if p.is_file():\n",
    "                newp = move_with_rename(p, INBOX)\n",
    "                moved.append(newp)\n",
    "\n",
    "        if moved:\n",
    "            print(f\"üì¶ Moved {len(moved)} file to inbox\")\n",
    "\n",
    "        # 2) Ambil snapshot file inbox SAAT INI (biar aman)\n",
    "        inbox_files = [p for p in INBOX.iterdir() if p.is_file()]\n",
    "        if not inbox_files:\n",
    "            print(\"‚è≥ Tidak ada file baru, skip upload\")\n",
    "        else:\n",
    "            print(f\"üì§ Uploading {len(inbox_files)} file...\")\n",
    "\n",
    "            # Upload folder inbox\n",
    "            api.upload_folder(\n",
    "                repo_id=REPO_ID,\n",
    "                repo_type=\"dataset\",\n",
    "                folder_path=str(INBOX),\n",
    "                path_in_repo=PATH_IN_REPO,\n",
    "                commit_message=f\"auto upload {SUBJECT}\"\n",
    "            )\n",
    "\n",
    "            # 3) Kalau sukses, HAPUS file yang barusan diupload\n",
    "            deleted = 0\n",
    "            for p in inbox_files:\n",
    "                try:\n",
    "                    p.unlink(missing_ok=True)  # py>=3.8\n",
    "                    deleted += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Gagal delete {p.name}: {e}\")\n",
    "\n",
    "            print(f\"‚úÖ Upload sukses (deleted {deleted}/{len(inbox_files)} file dari inbox)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Error (aman, lanjut loop):\", e)\n",
    "\n",
    "    print(f\"üò¥ Sleep {INTERVAL}s...\\n\")\n",
    "    time.sleep(INTERVAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7b601-4fd0-4b8a-a20f-0e111245b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf runpod-slim/7*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e61599-cbff-462b-99ad-578f442b5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf runpod-slim/blackwidof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c165e32-b739-4f8f-92c8-c2a4bc6b4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `hf`CLI if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "The token `model-mfn` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `model-mfn`\n",
      "ava+logos-l14-linearMSE.pth: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.71M/3.71M [00:00<00:00, 6.38MB/s]\n",
      "/workspace/runpod-slim/ComfyUI/models/aesthetic/ava+logos-l14-linearMSE.pth\n",
      "ava+logos-l14-reluMSE.pth: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.71M/3.71M [00:00<00:00, 14.8MB/s]\n",
      "/workspace/runpod-slim/ComfyUI/models/aesthetic/ava+logos-l14-reluMSE.pth\n",
      "sac+logos+ava1-l14-linearMSE.pth: 100%|‚ñà‚ñà‚ñà‚ñà| 3.71M/3.71M [00:00<00:00, 6.34MB/s]\n",
      "/workspace/runpod-slim/ComfyUI/models/aesthetic/sac+logos+ava1-l14-linearMSE.pth\n",
      "chadscorer.pth: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.71M/3.71M [00:00<00:00, 4.97MB/s]\n",
      "/workspace/runpod-slim/ComfyUI/models/aesthetic/chadscorer.pth\n"
     ]
    }
   ],
   "source": [
    "!hf auth login --token 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\n",
    "!hf download Esddin/venv \"ava+logos-l14-linearMSE.pth\" --local-dir /workspace/runpod-slim/ComfyUI/models/aesthetic\n",
    "!hf download Esddin/venv \"ava+logos-l14-reluMSE.pth\" --local-dir /workspace/runpod-slim/ComfyUI/models/aesthetic\n",
    "!hf download Esddin/venv \"sac+logos+ava1-l14-linearMSE.pth\" --local-dir /workspace/runpod-slim/ComfyUI/models/aesthetic\n",
    "!hf download Esddin/venv \"chadscorer.pth\" --local-dir /workspace/runpod-slim/ComfyUI/models/aesthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b55c4ef3-44a8-4f44-b675-a2bb5927070b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/workspace/runpod-slim/ComfyUI/custom_nodes/nodes'...\n",
      "remote: Enumerating objects: 189, done.\u001b[K\n",
      "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
      "remote: Compressing objects: 100% (169/169), done.\u001b[K\n",
      "remote: Total 189 (delta 94), reused 0 (delta 0), pack-reused 15 (from 1)\u001b[K\n",
      "Receiving objects: 100% (189/189), 52.41 KiB | 17.47 MiB/s, done.\n",
      "Resolving deltas: 100% (97/97), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf /workspace/runpod-slim/ComfyUI/custom_nodes/nodes\n",
    "!git clone https://Esddin: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@huggingface.co/datasets/Esddin/nodes --branch master /workspace/runpod-slim/ComfyUI/custom_nodes/nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27dbda6f-2bf6-45c4-91a4-7209f5e3385e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aesthetic-predictor-v2-5\n",
      "  Downloading aesthetic_predictor_v2_5-2024.12.18.1-py2.py3-none-any.whl.metadata (42 kB)\n",
      "Collecting accelerate>=0.30 (from aesthetic-predictor-v2-5)\n",
      "  Using cached accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from aesthetic-predictor-v2-5) (2.3.5)\n",
      "Requirement already satisfied: torch>=2.2 in /usr/local/lib/python3.12/dist-packages (from aesthetic-predictor-v2-5) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision>=0.17 in /usr/local/lib/python3.12/dist-packages (from aesthetic-predictor-v2-5) (0.21.0+cu124)\n",
      "Requirement already satisfied: transformers>=4.40 in /usr/local/lib/python3.12/dist-packages (from aesthetic-predictor-v2-5) (5.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30->aesthetic-predictor-v2-5) (26.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30->aesthetic-predictor-v2-5) (7.2.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30->aesthetic-predictor-v2-5) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30->aesthetic-predictor-v2-5) (1.3.7)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30->aesthetic-predictor-v2-5) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.30->aesthetic-predictor-v2-5) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.30->aesthetic-predictor-v2-5) (2025.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.30->aesthetic-predictor-v2-5) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.30->aesthetic-predictor-v2-5) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.30->aesthetic-predictor-v2-5) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.30->aesthetic-predictor-v2-5) (4.67.2)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.30->aesthetic-predictor-v2-5) (0.21.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.30->aesthetic-predictor-v2-5) (4.15.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=0.30->aesthetic-predictor-v2-5) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=0.30->aesthetic-predictor-v2-5) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=0.30->aesthetic-predictor-v2-5) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=0.30->aesthetic-predictor-v2-5) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=0.30->aesthetic-predictor-v2-5) (0.16.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch>=2.2->aesthetic-predictor-v2-5) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.17->aesthetic-predictor-v2-5) (12.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40->aesthetic-predictor-v2-5) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40->aesthetic-predictor-v2-5) (0.22.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.2->aesthetic-predictor-v2-5) (2.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub>=0.21.0->accelerate>=0.30->aesthetic-predictor-v2-5) (8.3.1)\n",
      "Downloading aesthetic_predictor_v2_5-2024.12.18.1-py2.py3-none-any.whl (28 kB)\n",
      "Using cached accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Installing collected packages: accelerate, aesthetic-predictor-v2-5\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/2\u001b[0m [aesthetic-predictor-v2-5]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.12.0 aesthetic-predictor-v2-5-2024.12.18.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-5u8b_8r0\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-5u8b_8r0\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ftfy (from clip==1.0)\n",
      "  Using cached ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (26.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2026.1.15)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (4.67.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (0.21.0+cu124)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->clip==1.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (2025.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->clip==1.0) (2.1.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->clip==1.0) (2.3.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->clip==1.0) (12.0.0)\n",
      "Using cached ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369549 sha256=00ecca1f4f250ea3eca6c8a9b19f52acd3a5f32bdd2874be24b767008f3eac17\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-etz2ffhz/wheels/35/3e/df/3d24cbfb3b6a06f17a2bfd7d1138900d4365d9028aa8f6e92f\n",
      "Successfully built clip\n",
      "Installing collected packages: ftfy, clip\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/2\u001b[0m [clip]\n",
      "\u001b[1A\u001b[2KSuccessfully installed clip-1.0 ftfy-6.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-2.6.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (4.67.2)\n",
      "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (6.0.3)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2025.12.0)\n",
      "Collecting torchmetrics>0.7.0 (from pytorch_lightning)\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (26.0)\n",
      "Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning) (4.15.0)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.13.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.11)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (70.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.20.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics>0.7.0->pytorch_lightning) (2.3.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (2.1.5)\n",
      "Downloading pytorch_lightning-2.6.1-py3-none-any.whl (857 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m857.3/857.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [pytorch_lightning]pytorch_lightning]\n",
      "\u001b[1A\u001b[2KSuccessfully installed lightning-utilities-0.15.2 pytorch_lightning-2.6.1 torchmetrics-1.8.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install aesthetic-predictor-v2-5\n",
    "!pip install git+https://github.com/openai/CLIP.git\n",
    "!pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc59b39-2ee0-47aa-a66e-9ee4bbb33ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from math import ceil\n",
    "\n",
    "SRC_DIR = \"/workspace/runpod-slim/ComfyUI/input/raw/ase.sese\"\n",
    "FILES_PER_FOLDER = 300\n",
    "PREFIX = \"ase.sese\"\n",
    "\n",
    "files = [\n",
    "    f for f in os.listdir(SRC_DIR)\n",
    "    if os.path.isfile(os.path.join(SRC_DIR, f))\n",
    "]\n",
    "\n",
    "files.sort()\n",
    "total_files = len(files)\n",
    "\n",
    "print(f\"Total file ditemukan: {total_files}\")\n",
    "\n",
    "# ‚úÖ GUARD CHECK TANPA SystemExit\n",
    "if total_files <= FILES_PER_FOLDER:\n",
    "    print(\"‚ùå File ‚â§ 300 ‚Üí tidak perlu dibagi. Script berhenti.\")\n",
    "else:\n",
    "    total_parts = ceil(total_files / FILES_PER_FOLDER)\n",
    "    print(f\"‚úÖ Akan dibagi menjadi {total_parts} folder\\n\")\n",
    "\n",
    "    for i in range(total_parts):\n",
    "        start = i * FILES_PER_FOLDER\n",
    "        end = start + FILES_PER_FOLDER\n",
    "        chunk = files[start:end]\n",
    "\n",
    "        part_dir = os.path.join(\n",
    "            SRC_DIR,\n",
    "            f\"{PREFIX}_{str(i+1).zfill(3)}\"\n",
    "        )\n",
    "        os.makedirs(part_dir, exist_ok=True)\n",
    "\n",
    "        for filename in chunk:\n",
    "            src = os.path.join(SRC_DIR, filename)\n",
    "            dst = os.path.join(part_dir, filename)\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "        print(f\"‚úî {part_dir} ‚Üí {len(chunk)} file\")\n",
    "\n",
    "    print(\"\\nüéâ Selesai\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "959fde52-b8b8-4c64-b2f3-7400cf5f9b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂ Run 1 / 1\n",
      "{\"prompt_id\": \"61e4884e-25dc-45d7-9a7c-2a292a751307\", \"number\": 0, \"node_errors\": {}}‚úî Done 1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "COUNT=100\n",
    "\n",
    "if [[ -z \"$COUNT\" ]]; then\n",
    "  echo \"Usage: $0 <jumlah_loop>\"\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "for ((i=1; i<=COUNT; i++)); do\n",
    "  echo \"‚ñ∂ Run $i / $COUNT\"\n",
    "\n",
    "  curl -s -X POST http://127.0.0.1:8188/prompt \\\n",
    "    -H \"Content-Type: application/json\" \\\n",
    "    -d @ANNVIDEOV1.2.json\n",
    "\n",
    "  echo \"‚úî Done $i\"\n",
    "done\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
